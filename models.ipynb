{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from torch import nn\n",
    "\n",
    "from data import get_loaders, load_dataset, train_test_split\n",
    "from training import test_step, train_step, train_model, get_test_predictions\n",
    "from utils import print_losses\n",
    "from swag import sample_from_SWAG, run_SWAG, calculate_sigma\n",
    "from definitions import DATASETS, device\n",
    "from models import create_model, load_model\n",
    "from metrics import RMSE\n",
    "from swag_mod import calculate_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_mod(\n",
    "    batch_x: torch.Tensor,\n",
    "    batch_y: torch.Tensor,\n",
    "    model: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion,\n",
    "    lr_multipliers,\n",
    "):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(batch_x.to(device))\n",
    "    loss = criterion(outputs, batch_y.to(device))\n",
    "    loss.backward()\n",
    "    multitiply_grads(model, lr_multipliers)\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def train_SWAG_mod(\n",
    "    x_train: np.array,\n",
    "    y_train: np.array,\n",
    "    x_test: np.array,\n",
    "    y_test: np.array,\n",
    "    model: nn.Module,\n",
    "    K,\n",
    "    lr_multipliers,\n",
    "    epochs: int = 100,\n",
    "    batch_size: int = 100,\n",
    "    lr: float = 0.01,\n",
    "    verbose: bool = True,\n",
    "    c=1,\n",
    "    momentum=0,\n",
    "    weight_decay=0,\n",
    "):\n",
    "    assert c >= 1 and K >= 2\n",
    "#     train_loader, test_loader = get_loaders(x_train, y_train, x_test, y_test, batch_size)\n",
    "    train_loader, _, test_loader = get_loaders(x_train, y_train, x_test, y_test, batch_size, val_loader=True)\n",
    "    theta_epoch = torch.nn.utils.parameters_to_vector(model.parameters()).detach().cpu().clone()\n",
    "    theta = theta_epoch.clone()\n",
    "    theta_square = theta_epoch.clone() ** 2\n",
    "    D = None\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    train_losses = [test_step(batch_x, batch_y, model, criterion) for batch_x, batch_y in train_loader]\n",
    "    test_losses = [test_step(batch_x, batch_y, model, criterion) for batch_x, batch_y in test_loader]\n",
    "    if verbose:\n",
    "        print_losses(0, train_losses, test_losses)\n",
    "\n",
    "    thetas = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_losses = [train_step_mod(batch_x, batch_y, model, optimizer, criterion, lr_multipliers) \n",
    "                        for batch_x, batch_y in train_loader]\n",
    "        test_losses = [test_step(batch_x, batch_y, model, criterion) for batch_x, batch_y in test_loader]\n",
    "        if verbose:\n",
    "            print_losses(epoch, train_losses, test_losses)\n",
    "        if epoch % c == 0:\n",
    "            if verbose:\n",
    "                print(\"SWAG moment update\")\n",
    "            n = epoch / c\n",
    "            theta_epoch = torch.nn.utils.parameters_to_vector(model.parameters()).detach().cpu().clone()\n",
    "            thetas.append(theta_epoch.clone())\n",
    "            theta = (n * theta + theta_epoch.clone()) / (n + 1)\n",
    "            theta_square = (n * theta_square + theta_epoch.clone() ** 2) / (n + 1)\n",
    "            deviations = (theta_epoch.clone() - theta).reshape(-1, 1)\n",
    "            if D is None:\n",
    "                D = deviations\n",
    "            else:\n",
    "                if D.shape[1] == K:\n",
    "                    D = D[:, 1:]\n",
    "                D = torch.cat((D, deviations), dim=1)\n",
    "    sigma_diag = theta_square - theta ** 2\n",
    "    torch.nn.utils.vector_to_parameters(theta, model.parameters())\n",
    "    model.to(device)\n",
    "    test_losses = [test_step(batch_x, batch_y, model, criterion) for batch_x, batch_y in test_loader]\n",
    "    # print(f\"Finished SWAG.     Best test loss: {np.mean(test_losses):.5f}\")\n",
    "    return theta, sigma_diag, D, thetas\n",
    "\n",
    "def multitiply_grads(model, lr_multipliers):\n",
    "    start_ind = 0\n",
    "    for params in model.parameters():\n",
    "        shape = params.shape\n",
    "        total_len = params.reshape(-1).shape[0]\n",
    "        multipliers = lr_multipliers[start_ind:(start_ind + total_len)].reshape(shape)\n",
    "        start_ind += total_len\n",
    "        params.grad = params.grad * multipliers.to(device)\n",
    "        \n",
    "def sample_and_get_metrics(x_train, y_train, x_test, y_test, model, theta_swa, sigma_diag, D, K, S):\n",
    "    samples = sample_from_SWAG(x_train, y_train, x_test, y_test, model, theta_swa, sigma_diag, D, K, S)\n",
    "    samples_array = np.concatenate(samples, axis=1)\n",
    "    y_pred = samples_array.mean(axis=1, keepdims=True)\n",
    "    y_l = np.percentile(samples_array, 2.5, axis=1, keepdims=True)\n",
    "    y_u = np.percentile(samples_array, 97.5, axis=1, keepdims=True)\n",
    "    rmse = RMSE(y_pred, y_test)\n",
    "    pcip = np.mean((y_l < y_test) & (y_test < y_u))\n",
    "    mpiw = np.mean(y_u - y_l)\n",
    "    return rmse, pcip, mpiw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 556\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boston_housing',\n",
       " 'concrete',\n",
       " 'energy_heating_load',\n",
       " 'power',\n",
       " 'wine',\n",
       " 'yacht',\n",
       " 'kin8nm',\n",
       " 'naval_compressor_decay']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSELECTED = [\n",
    "    'boston_housing',\n",
    "    'concrete',\n",
    "    'energy_heating_load',\n",
    "    'power',\n",
    "    'wine',\n",
    "    'yacht',\n",
    "    'kin8nm',\n",
    "    'naval_compressor_decay',\n",
    "#     'protein',\n",
    "#     'year_prediction_msd',\n",
    "            ]\n",
    "DSELECTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # SWAG LOOP\n",
    "\n",
    "# # for dataset_name in DATASETS:\n",
    "# for dataset_name in DSELECTED:\n",
    "# # for dataset_name in ['boston_housing']:\n",
    "#     run_SWAG(dataset_name, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOLERANCE = {\n",
    "    \"boston_housing\": 0.06,\n",
    "    \"concrete\": 0.05,\n",
    "    \"energy_heating_load\": 0.05,\n",
    "    \"kin8nm\": 0.04,\n",
    "    \"naval_compressor_decay\": 0.04,\n",
    "    \"power\": 0.05,\n",
    "    \"protein\": 0.05,\n",
    "    \"wine\": 0.02,\n",
    "    \"yacht\": 0.03,\n",
    "    \"year_prediction_msd\": 0.05,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================\n",
      "dataset: boston_housing, rows: 506, columns: 13, range of x: [0.0, 711.0], range of y: [5.0, 50.0]\n",
      "SGD RMSE: 0.334\n",
      "SWAG_lr:  0.01000\n",
      "RMSE: 0.306, PICP: 0.333, MPIW:0.280\n",
      "-----> TOLERANCE: 0.06\n",
      "Test RMSE: 0.338, PICP: 0.686, MPIW:0.834 | Val RMSE: 0.415, PICP: 0.848, MPIW:1.145\n",
      "========================================================================================\n",
      "dataset: concrete, rows: 1030, columns: 8, range of x: [0.0, 1145.0], range of y: [2.33, 82.6]\n",
      "SGD RMSE: 0.581\n",
      "SWAG_lr:  0.20000\n",
      "RMSE: 0.338, PICP: 0.825, MPIW:0.971\n",
      "-----> TOLERANCE: 0.05\n",
      "Test RMSE: 0.535, PICP: 0.718, MPIW:1.178 | Val RMSE: 0.552, PICP: 0.710, MPIW:1.185\n",
      "========================================================================================\n",
      "dataset: energy_heating_load, rows: 768, columns: 8, range of x: [0.0, 808.5], range of y: [6.01, 43.1]\n",
      "SGD RMSE: 0.232\n",
      "SWAG_lr:  0.10000\n",
      "RMSE: 0.203, PICP: 0.805, MPIW:0.472\n",
      "-----> TOLERANCE: 0.05\n",
      "Some error\n",
      "Test RMSE: 0.172, PICP: 0.909, MPIW:0.744 | Val RMSE: 0.224, PICP: 0.843, MPIW:0.723\n",
      "========================================================================================\n",
      "dataset: kin8nm, rows: 8192, columns: 8, range of x: [-1.5706812, 1.5707529], range of y: [0.040165378, 1.4585206]\n",
      "SGD RMSE: 0.474\n",
      "SWAG_lr:  0.10000\n",
      "RMSE: 0.511, PICP: 0.939, MPIW:2.123\n",
      "-----> TOLERANCE: 0.04\n",
      "Some error\n",
      "Some error\n",
      "Some error\n",
      "Test RMSE: 0.416, PICP: 0.711, MPIW:0.840 | Val RMSE: 0.410, PICP: 0.732, MPIW:0.859\n",
      "========================================================================================\n",
      "dataset: naval_compressor_decay, rows: 11934, columns: 16, range of x: [0.0, 72784.872], range of y: [0.95, 1.0]\n",
      "SGD RMSE: 1.364\n",
      "SWAG_lr:  0.01000\n",
      "RMSE: 1.709, PICP: 0.000, MPIW:0.250\n",
      "-----> TOLERANCE: 0.04\n",
      "Some error\n",
      "Some error\n",
      "Some error\n",
      "Test RMSE: 1.736, PICP: 0.000, MPIW:1.315 | Val RMSE: 1.445, PICP: 0.000, MPIW:1.401\n",
      "========================================================================================\n",
      "dataset: power, rows: 9568, columns: 4, range of x: [1.81, 1033.3], range of y: [420.26, 495.76]\n",
      "SGD RMSE: 0.250\n",
      "SWAG_lr:  0.20000\n",
      "RMSE: 0.254, PICP: 0.619, MPIW:0.444\n",
      "-----> TOLERANCE: 0.05\n",
      "Some error\n",
      "Some error\n",
      "Test RMSE: 0.245, PICP: 0.287, MPIW:0.196 | Val RMSE: 0.241, PICP: 0.295, MPIW:0.191\n",
      "========================================================================================\n",
      "dataset: protein, rows: 45730, columns: 9, range of x: [0.0, 5472011.4075], range of y: [0.0, 20.999]\n",
      "SGD RMSE: 0.823\n",
      "SWAG_lr:  0.20000\n",
      "RMSE: 0.801, PICP: 0.251, MPIW:0.591\n",
      "-----> TOLERANCE: 0.05\n",
      "Some error\n",
      "Some error\n",
      "Some error\n",
      "Test RMSE: 0.799, PICP: 0.266, MPIW:0.635 | Val RMSE: 0.798, PICP: 0.258, MPIW:0.620\n",
      "========================================================================================\n",
      "dataset: wine, rows: 1599, columns: 11, range of x: [0.0, 289.0], range of y: [3, 8]\n",
      "SGD RMSE: 0.894\n",
      "SWAG_lr:  0.05000\n",
      "RMSE: 0.852, PICP: 0.331, MPIW:0.671\n",
      "-----> TOLERANCE: 0.02\n",
      "Some error\n",
      "Some error\n",
      "Some error\n",
      "Test RMSE: 0.862, PICP: 0.094, MPIW:0.239 | Val RMSE: 0.729, PICP: 0.097, MPIW:0.251\n",
      "========================================================================================\n",
      "dataset: yacht, rows: 308, columns: 6, range of x: [-5.0, 5.35], range of y: [0.01, 62.42]\n",
      "SGD RMSE: 0.314\n",
      "SWAG_lr:  0.10000\n",
      "RMSE: 0.195, PICP: 0.548, MPIW:0.430\n",
      "-----> TOLERANCE: 0.03\n",
      "Some error\n",
      "Test RMSE: 0.117, PICP: 0.968, MPIW:0.594 | Val RMSE: 0.138, PICP: 1.000, MPIW:0.512\n",
      "========================================================================================\n",
      "dataset: year_prediction_msd, rows: 515345, columns: 90, range of x: [-14861.69535, 65735.77953], range of y: [1922, 2011]\n",
      "SGD RMSE: 0.830\n",
      "SWAG_lr:  0.01000\n",
      "RMSE: 0.830, PICP: 0.149, MPIW:0.241\n",
      "-----> TOLERANCE: 0.05\n",
      "Some error\n",
      "Some error\n",
      "Some error\n",
      "Test RMSE: 0.822, PICP: 0.297, MPIW:0.476 | Val RMSE: 0.808, PICP: 0.310, MPIW:0.484\n"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "S = 500\n",
    "weight_decay = 0\n",
    "multiplier = 2\n",
    "# tolerance = 0.05\n",
    "# for dataset_name in ['boston_housing']:\n",
    "# for dataset_name in ['yacht']:\n",
    "# for dataset_name in ['year_prediction_msd']:\n",
    "# for dataset_name in ['naval_compressor_decay']:\n",
    "#     for dataset_name in DATASETS[:3]:\n",
    "for dataset_name in DATASETS:\n",
    "#     for dataset_name in ['naval_compressor_decay']:\n",
    "    if dataset_name in TOLERANCE:\n",
    "        run_SWAG(dataset_name, weight_decay=0, train_model_flag=False)\n",
    "        tolerance = TOLERANCE[dataset_name]\n",
    "        print(f\"\"\"-----> TOLERANCE: {tolerance}\"\"\")\n",
    "        x_train, y_train, x_test, y_test, _, _ = load_dataset(dataset_name, verbose=False)\n",
    "        batch_size = x_train.shape[0]//9\n",
    "        model = create_model(x_train, layer_dims=[50], verbose=False)\n",
    "    #     train_model(x_train, y_train, x_test, y_test, model, dataset_name, lr=0.001, epochs=50000, verbose=False, \n",
    "    #                 batch_size=batch_size, weight_decay=weight_decay)\n",
    "        model = load_model(model, f\"best_model_weights-{dataset_name}.pth\", verbose=False)\n",
    "        y_pred = get_test_predictions(x_train, y_train, x_test, y_test, model)\n",
    "    #     print(f\"SGD RMSE: {RMSE(y_pred, y_test):.3f}\")\n",
    "#         print(\"---MOD---\")\n",
    "        theta_epoch = torch.nn.utils.parameters_to_vector(model.parameters()).detach().cpu().clone()\n",
    "        lr_multipliers = torch.ones_like(theta_epoch).float()\n",
    "        round_results = []\n",
    "        for rounds in range(10):\n",
    "            try:\n",
    "                model = load_model(model, f\"best_model_weights-{dataset_name}.pth\", verbose=False)\n",
    "                theta_swa, sigma_diag, D, thetas = train_SWAG_mod(x_train, y_train, x_test, y_test, model, K, lr_multipliers,\n",
    "                                                              verbose=False, lr=0.01, batch_size=batch_size, \n",
    "                                                              weight_decay=weight_decay, epochs=50)\n",
    "                weight_series = torch.stack(thetas).numpy()\n",
    "#                 step_plot = weight_series.shape[1] // 5\n",
    "                weight_series -= weight_series.mean(axis=0, keepdims=True)\n",
    "                weight_series /= weight_series.std(axis=0, keepdims=True) + 1e-10\n",
    "    #             plt.plot(weight_series[:,::step_plot], alpha=0.3)\n",
    "    #             plt.show()\n",
    "                coeffs = calculate_coeffs(weight_series, False)\n",
    "                lr_multipliers[np.abs(coeffs) > tolerance] *= multiplier\n",
    "                _, x_val, _, y_val = train_test_split(x_train, y_train, test_size=0.1)\n",
    "                y_val_pred = model(torch.from_numpy(x_val).float().to(device)).detach().cpu().numpy()\n",
    "                sigma_diag = torch.clamp(sigma_diag, min=1e-10)\n",
    "                rmse_test, pcip_test, mpiw_test = sample_and_get_metrics(x_train, y_train, x_test, y_test, \n",
    "                                                                         model, theta_swa, sigma_diag, D, K, S)\n",
    "                rmse_val, pcip_val, mpiw_val = sample_and_get_metrics(x_train, y_train, x_val, y_val, \n",
    "                                                                         model, theta_swa, sigma_diag, D, K, S)\n",
    "                round_results.append([rmse_test, pcip_test, mpiw_test, rmse_val, pcip_val, mpiw_val])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "#                 raise e\n",
    "#                 print(\"Some error\")\n",
    "        best_ind = np.array(round_results)[:,3].argmin()\n",
    "        rmse_test, pcip_test, mpiw_test, rmse_val, pcip_val, mpiw_val = round_results[best_ind]\n",
    "        print(f\"Test RMSE: {rmse_test:.3f}, PICP: {pcip_test:.3f}, MPIW:{mpiw_test:.3f} \", end = \"| \")\n",
    "        print(f\"Val RMSE: {rmse_val:.3f}, PICP: {pcip_val:.3f}, MPIW:{mpiw_val:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================\n",
      "dataset: boston_housing, rows: 506, columns: 13, range of x: [0.0, 711.0], range of y: [5.0, 50.0]\n",
      "SGD RMSE: 0.652\n",
      "SWAG_lr:  0.01000\n",
      "RMSE: 0.388, PICP: 0.392, MPIW:0.324\n",
      "-----> TOLERANCE: 0.05\n",
      "0.00011692351\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32663/1203847004.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m                                                                          model, theta_swa, sigma_diag, D, K, S)\n\u001b[1;32m     49\u001b[0m                 rmse_val, pcip_val, mpiw_val = sample_and_get_metrics(x_train, y_train, x_val, y_val, \n\u001b[0;32m---> 50\u001b[0;31m                                                                          model, theta_swa, sigma_diag, D, K, S)\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m#                 raise e\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_32663/578884322.py\u001b[0m in \u001b[0;36msample_and_get_metrics\u001b[0;34m(x_train, y_train, x_test, y_test, model, theta_swa, sigma_diag, D, K, S)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msample_and_get_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_swa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_diag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_from_SWAG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_swa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_diag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0msamples_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/phd/ProbAI/homework/probai2021/swag.py\u001b[0m in \u001b[0;36msample_from_SWAG\u001b[0;34m(x_train, y_train, x_test, y_test, model, theta_swa, sigma_diag, D, K, S)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mtest_predictions_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0msampled_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_posterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_swa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_diag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_to_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/phd/ProbAI/homework/probai2021/swag.py\u001b[0m in \u001b[0;36msample_posterior\u001b[0;34m(theta_swa, sigma_diag, D, K)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta_swa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_sigma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma_diag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariance_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/phd/ProbAI/homework/probai2021/swag.py\u001b[0m in \u001b[0;36mcalculate_sigma\u001b[0;34m(sigma_diag, D, K)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_sigma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma_diag\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma_diag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "S = 500\n",
    "weight_decay = 0\n",
    "multiplier = 2\n",
    "tolerance = 0.05\n",
    "# for dataset_name in ['boston_housing']:\n",
    "# for dataset_name in ['yacht']:\n",
    "# for dataset_name in ['year_prediction_msd']:\n",
    "# for dataset_name in ['naval_compressor_decay']:\n",
    "#     for dataset_name in DATASETS[:3]:\n",
    "for dataset_name in DATASETS:\n",
    "#     for dataset_name in ['naval_compressor_decay']:\n",
    "#     if dataset_name in TOLERANCE:\n",
    "#         continue\n",
    "    run_SWAG(dataset_name, weight_decay=0, train_model_flag=False)\n",
    "    for tolerance in np.linspace(0.05, 0.08, 8):\n",
    "        print(f\"\"\"-----> TOLERANCE: {tolerance}\"\"\")\n",
    "        x_train, y_train, x_test, y_test, _, _ = load_dataset(dataset_name, verbose=False)\n",
    "        batch_size = x_train.shape[0]//9\n",
    "        model = create_model(x_train, layer_dims=[50], verbose=False)\n",
    "    #     train_model(x_train, y_train, x_test, y_test, model, dataset_name, lr=0.001, epochs=50000, verbose=False, \n",
    "    #                 batch_size=batch_size, weight_decay=weight_decay)\n",
    "        model = load_model(model, f\"best_model_weights-{dataset_name}.pth\", verbose=False)\n",
    "        y_pred = get_test_predictions(x_train, y_train, x_test, y_test, model)\n",
    "    #     print(f\"SGD RMSE: {RMSE(y_pred, y_test):.3f}\")\n",
    "#         print(\"---MOD---\")\n",
    "        theta_epoch = torch.nn.utils.parameters_to_vector(model.parameters()).detach().cpu().clone()\n",
    "        lr_multipliers = torch.ones_like(theta_epoch).float()\n",
    "        for rounds in range(10):\n",
    "            try:\n",
    "                model = load_model(model, f\"best_model_weights-{dataset_name}.pth\", verbose=False)\n",
    "                theta_swa, sigma_diag, D, thetas = train_SWAG_mod(x_train, y_train, x_test, y_test, model, K, lr_multipliers,\n",
    "                                                              verbose=False, lr=0.01, batch_size=batch_size, \n",
    "                                                              weight_decay=weight_decay, epochs=50)\n",
    "                print(torch.diagonal(calculate_sigma(sigma_diag, D, K)).numpy().mean())\n",
    "                weight_series = torch.stack(thetas).numpy()\n",
    "#                 step_plot = weight_series.shape[1] // 5\n",
    "                weight_series -= weight_series.mean(axis=0, keepdims=True)\n",
    "                weight_series /= weight_series.std(axis=0, keepdims=True) + 1e-10\n",
    "    #             plt.plot(weight_series[:,::step_plot], alpha=0.3)\n",
    "    #             plt.show()\n",
    "                coeffs = calculate_coeffs(weight_series, False)\n",
    "                lr_multipliers[np.abs(coeffs) > tolerance] *= multiplier\n",
    "                _, x_val, _, y_val = train_test_split(x_train, y_train, test_size=0.1)\n",
    "                y_val_pred = model(torch.from_numpy(x_val).float().to(device)).detach().cpu().numpy()\n",
    "                sigma_diag = torch.clamp(sigma_diag, min=1e-10)\n",
    "                rmse_test, pcip_test, mpiw_test = sample_and_get_metrics(x_train, y_train, x_test, y_test, \n",
    "                                                                         model, theta_swa, sigma_diag, D, K, S)\n",
    "                rmse_val, pcip_val, mpiw_val = sample_and_get_metrics(x_train, y_train, x_val, y_val, \n",
    "                                                                         model, theta_swa, sigma_diag, D, K, S)\n",
    "            except Exception as e:\n",
    "#                 raise e\n",
    "                print(\"Some error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.optim.Adam()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probai",
   "language": "python",
   "name": "probai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
