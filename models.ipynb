{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from torch import nn\n",
    "\n",
    "from data import get_loaders, load_dataset, train_test_split\n",
    "from training import test_step, train_step, train_model, get_test_predictions\n",
    "from utils import print_losses\n",
    "from swag import sample_from_SWAG, run_SWAG\n",
    "from definitions import DATASETS\n",
    "from models import create_model, load_model\n",
    "from metrics import RMSE\n",
    "from swag_mod import calculate_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_mod(\n",
    "    batch_x: torch.Tensor,\n",
    "    batch_y: torch.Tensor,\n",
    "    model: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion,\n",
    "    lr_multipliers,\n",
    "):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(batch_x)\n",
    "    loss = criterion(outputs, batch_y)\n",
    "    loss.backward()\n",
    "    multitiply_grads(model, lr_multipliers)\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def train_SWAG_mod(\n",
    "    x_train: np.array,\n",
    "    y_train: np.array,\n",
    "    x_test: np.array,\n",
    "    y_test: np.array,\n",
    "    model: nn.Module,\n",
    "    K,\n",
    "    lr_multipliers,\n",
    "    epochs: int = 100,\n",
    "    batch_size: int = 100,\n",
    "    lr: float = 0.1,\n",
    "    verbose: bool = True,\n",
    "    c=1,\n",
    "    momentum=0,\n",
    "    weight_decay=0,\n",
    "):\n",
    "    assert c >= 1 and K >= 2\n",
    "#     train_loader, test_loader = get_loaders(x_train, y_train, x_test, y_test, batch_size)\n",
    "    train_loader, _, test_loader = get_loaders(x_train, y_train, x_test, y_test, batch_size, val_loader=True)\n",
    "    theta_epoch = torch.nn.utils.parameters_to_vector(model.parameters()).detach().cpu().clone()\n",
    "    theta = theta_epoch.clone()\n",
    "    theta_square = theta_epoch.clone() ** 2\n",
    "    D = None\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    train_losses = [test_step(batch_x, batch_y, model, criterion) for batch_x, batch_y in train_loader]\n",
    "    test_losses = [test_step(batch_x, batch_y, model, criterion) for batch_x, batch_y in test_loader]\n",
    "    if verbose:\n",
    "        print_losses(0, train_losses, test_losses)\n",
    "\n",
    "    thetas = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_losses = [train_step_mod(batch_x, batch_y, model, optimizer, criterion, lr_multipliers) \n",
    "                        for batch_x, batch_y in train_loader]\n",
    "        test_losses = [test_step(batch_x, batch_y, model, criterion) for batch_x, batch_y in test_loader]\n",
    "        if verbose:\n",
    "            print_losses(epoch, train_losses, test_losses)\n",
    "        if epoch % c == 0:\n",
    "            if verbose:\n",
    "                print(\"SWAG moment update\")\n",
    "            n = epoch / c\n",
    "            theta_epoch = torch.nn.utils.parameters_to_vector(model.parameters()).detach().cpu().clone()\n",
    "            thetas.append(theta_epoch.clone())\n",
    "            theta = (n * theta + theta_epoch.clone()) / (n + 1)\n",
    "            theta_square = (n * theta_square + theta_epoch.clone() ** 2) / (n + 1)\n",
    "            deviations = (theta_epoch.clone() - theta).reshape(-1, 1)\n",
    "            if D is None:\n",
    "                D = deviations\n",
    "            else:\n",
    "                if D.shape[1] == K:\n",
    "                    D = D[:, 1:]\n",
    "                D = torch.cat((D, deviations), dim=1)\n",
    "    sigma_diag = theta_square - theta ** 2\n",
    "    torch.nn.utils.vector_to_parameters(theta, model.parameters())\n",
    "    test_losses = [test_step(batch_x, batch_y, model, criterion) for batch_x, batch_y in test_loader]\n",
    "    # print(f\"Finished SWAG.     Best test loss: {np.mean(test_losses):.5f}\")\n",
    "    return theta, sigma_diag, D, thetas\n",
    "\n",
    "def multitiply_grads(model, lr_multipliers):\n",
    "    start_ind = 0\n",
    "    for params in model.parameters():\n",
    "        shape = params.shape\n",
    "        total_len = params.reshape(-1).shape[0]\n",
    "        multipliers = lr_multipliers[start_ind:(start_ind + total_len)].reshape(shape)\n",
    "        start_ind += total_len\n",
    "        params.grad = params.grad * multipliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSELECTED = [\n",
    "    'boston_housing',\n",
    "    'concrete',\n",
    "    'energy_heating_load',\n",
    "#     'kin8nm',\n",
    "#     'naval_compressor_decay',\n",
    "    'power',\n",
    "#     'protein',\n",
    "    'wine',\n",
    "    'yacht',\n",
    "#     'year_prediction_msd',\n",
    "            ]\n",
    "DSELECTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SWAG LOOP\n",
    "\n",
    "# for dataset_name in DATASETS:\n",
    "for dataset_name in DSELECTED:\n",
    "    run_SWAG(dataset_name, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "K = 10\n",
    "S = 500\n",
    "weight_decay = 0\n",
    "multiplier = 2\n",
    "tolerance = 0.05\n",
    "# for dataset_name in ['boston_housing']:\n",
    "# for dataset_name in ['yacht']:\n",
    "# for dataset_name in ['year_prediction_msd']:\n",
    "# for dataset_name in ['naval_compressor_decay']:\n",
    "for tolerance in np.linspace(0.03, 0.07, 5):\n",
    "    print(f\"\"\"========================================================================================\n",
    "    \n",
    "    TOLERANCE: {tolerance}\n",
    "    \"\"\")\n",
    "#     for dataset_name in DATASETS[:3]:\n",
    "    for dataset_name in DSELECTED:\n",
    "#     for dataset_name in ['naval_compressor_decay']:\n",
    "        run_SWAG(dataset_name, weight_decay=0, train_model_flag=False)\n",
    "        x_train, y_train, x_test, y_test, _, _ = load_dataset(dataset_name, verbose=False)\n",
    "        batch_size = x_train.shape[0]//9\n",
    "        model = create_model(x_train, layer_dims=[50], verbose=False)\n",
    "    #     train_model(x_train, y_train, x_test, y_test, model, dataset_name, lr=0.001, epochs=50000, verbose=False, \n",
    "    #                 batch_size=batch_size, weight_decay=weight_decay)\n",
    "        model = load_model(model, f\"best_model_weights-{dataset_name}.pth\", verbose=False)\n",
    "        y_pred = get_test_predictions(x_train, y_train, x_test, y_test, model)\n",
    "    #     print(f\"SGD RMSE: {RMSE(y_pred, y_test):.3f}\")\n",
    "        print(\"---MOD---\")\n",
    "        theta_epoch = torch.nn.utils.parameters_to_vector(model.parameters()).detach().cpu().clone()\n",
    "        lr_multipliers = torch.ones_like(theta_epoch).float()\n",
    "        for rounds in range(15):\n",
    "            try:\n",
    "    #             print(0.001 * (2 ** (rounds)))\n",
    "                model = load_model(model, f\"best_model_weights-{dataset_name}.pth\", verbose=False)\n",
    "                theta_swa, sigma_diag, D, thetas = train_SWAG_mod(x_train, y_train, x_test, y_test, model, K, lr_multipliers,\n",
    "                                                              verbose=False, lr=0.001, batch_size=batch_size, \n",
    "                                                              weight_decay=weight_decay, epochs=50)\n",
    "                weight_series = torch.stack(thetas).numpy()\n",
    "                step_plot = weight_series.shape[1] // 5\n",
    "#                 print(weight_series.std(axis=0, keepdims=True))\n",
    "                weight_series -= weight_series.mean(axis=0, keepdims=True)\n",
    "                weight_series /= weight_series.std(axis=0, keepdims=True) + 1e-10\n",
    "#                 print(weight_series)\n",
    "    #             plt.plot(weight_series[:,::step_plot], alpha=0.3)\n",
    "    #             plt.show()\n",
    "                coeffs = calculate_coeffs(weight_series, False)\n",
    "#                 print(coeffs)\n",
    "                lr_multipliers[np.abs(coeffs) > tolerance] *= multiplier\n",
    "    #             print(lr_multipliers)\n",
    "                _, x_val, _, y_val = train_test_split(x_train, y_train, test_size=0.1)\n",
    "                y_val_pred = model(torch.from_numpy(x_val).float()).detach().cpu().numpy()\n",
    "                sigma_diag = torch.clamp(sigma_diag, min=1e-10)\n",
    "                samples = sample_from_SWAG(x_train, y_train, x_test, y_test, model, theta_swa, sigma_diag, D, K, S)\n",
    "                samples_array = np.concatenate(samples, axis=1)\n",
    "                y_pred = samples_array.mean(axis=1, keepdims=True)\n",
    "                y_l = np.percentile(samples_array, 2.5, axis=1, keepdims=True)\n",
    "                y_u = np.percentile(samples_array, 97.5, axis=1, keepdims=True)\n",
    "                print(f\"RMSE: {RMSE(y_pred, y_test):.3f}, PICP: {np.mean((y_l < y_test) & (y_test < y_u)):.3f}, MPIW:{np.mean(y_u - y_l):.3f}, val RMSE: {RMSE(y_val_pred, y_val):.3f}\")\n",
    "            except Exception as e:\n",
    "#                 raise e\n",
    "                print(\"Some error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probai",
   "language": "python",
   "name": "probai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
